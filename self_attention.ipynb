{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOTDaJe5615ys6QjeQrvYB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satani99/attention_is_all_you_need/blob/main/self_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTrvtUo22vRP",
        "outputId": "2c93a0bc-46fb-4f73-a01a-2d6c07181759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Life is short, eat dessert first\"\n",
        "\n",
        "dc = {s:i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "sentence_int = torch.tensor([dc[s] for s in sentence.replace(',', '').split()])\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayaWYWCLrx9s",
        "outputId": "972d86db-5962-47bc-bbaf-6ada5477286a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 5, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embed = torch.nn.Embedding(6, 16)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjtR3Xs_r_Lg",
        "outputId": "f2f629aa-afe1-4633-d8f6-d9f28fb861df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
            "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
            "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
            "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
            "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
            "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
            "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
            "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
            "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
            "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
            "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
            "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
            "torch.Size([6, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "d_q, d_k, d_v = 24, 24, 28 \n",
        "\n",
        "W_query = torch.rand(d_q, d)\n",
        "W_key = torch.rand(d_k, d)\n",
        "W_value = torch.rand(d_v, d)"
      ],
      "metadata": {
        "id": "6Ijf5yL_sdlb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = embedded_sentence[1]\n",
        "query_2 = W_query.matmul(x_2)\n",
        "key_2 = W_key.matmul(x_2)\n",
        "value_2 = W_value.matmul(x_2)\n",
        "\n",
        "print(query_2.shape)\n",
        "print(key_2.shape)\n",
        "print(value_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyD_LZrItuE3",
        "outputId": "3d7dcca6-6318-420f-ef4c-0798c94267a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24])\n",
            "torch.Size([24])\n",
            "torch.Size([28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = W_key.matmul(embedded_sentence.T).T\n",
        "values = W_value.matmul(embedded_sentence.T).T\n",
        "\n",
        "print(\"keys.shape\", keys.shape)\n",
        "print(\"values.shape\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w8baBTFuIKt",
        "outputId": "4b4502fd-091f-4f7d-d652-062335ac22d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape torch.Size([6, 24])\n",
            "values.shape torch.Size([6, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the unnormalized attention weight for the query \n",
        "# and the 5th input \n",
        "omega_24 = query_2.dot(keys[4])\n",
        "print(omega_24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBt7OLOQu9MB",
        "outputId": "a9eef7b5-289d-456b-ea9c-92f0c1860965"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11.1466)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_2 = query_2.matmul(keys.T)\n",
        "print(omega_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zpl5-NZv4fZ",
        "outputId": "ea3e27b4-7ef2-4fe3-fa80-442819af784b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.5808, -7.6597,  3.2558,  1.0395, 11.1466, -0.4800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the attention weights \n",
        "import torch.nn.functional as F \n",
        "\n",
        "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJRcdaRywOFT",
        "outputId": "f1e6cd92-3bb0-4691-bdf5-df95f4aa11b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2912, 0.0106, 0.0982, 0.0625, 0.4917, 0.0458])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_2 = attention_weights_2.matmul(values)\n",
        "\n",
        "print(context_vector_2.shape)\n",
        "print(context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AUV05P_xUEu",
        "outputId": "d248807c-bcdd-4132-8536-bd36c6999b40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28])\n",
            "tensor([-1.5993,  0.0156,  1.2670,  0.0032, -0.6460, -1.1407, -0.4908, -1.4632,\n",
            "         0.4747,  1.1926,  0.4506, -0.7110,  0.0602,  0.7125, -0.1628, -2.0184,\n",
            "         0.3838, -2.1188, -0.8136, -1.5694,  0.7934, -0.2911, -1.3640, -0.2366,\n",
            "        -0.9564, -0.5265,  0.0624,  1.7084])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Head Attention with example of 3 attention heads\n",
        "\n",
        "h = 3 \n",
        "multihead_W_query = torch.rand(h, d_q, d)\n",
        "multihead_W_key = torch.rand(h, d_k, d)\n",
        "multihead_W_value = torch.rand(h, d_v, d)\n",
        "print(multihead_W_query.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yokSjPetyLv-",
        "outputId": "24a07267-21ef-4bd8-bf92-f37e6693574d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 24, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_query_2 = multihead_W_query.matmul(x_2)\n",
        "print(multihead_query_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWJ7WaX2iCW",
        "outputId": "ba596d0f-7b3e-45d3-e2c8-c5b571b69227"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_key_2 = multihead_W_key.matmul(x_2)\n",
        "multihead_value_2 = multihead_W_value.matmul(x_2)"
      ],
      "metadata": {
        "id": "D-F2zoJa2xrv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_inputs = embedded_sentence.T.repeat(3, 1, 1)\n",
        "print(stacked_inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JHVNIet32rn",
        "outputId": "fda9f518-e5e1-4239-9340-a339e9f8db8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 16, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_keys = torch.bmm(multihead_W_key, stacked_inputs)\n",
        "multihead_values = torch.bmm(multihead_W_value, stacked_inputs)\n",
        "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
        "print(\"multihead_values.shape:\", multihead_values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRZHqrIT4EmF",
        "outputId": "953e7470-7f1a-40c4-8de6-84ded8882518"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multihead_keys.shape: torch.Size([3, 24, 6])\n",
            "multihead_values.shape: torch.Size([3, 28, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multihead_keys = multihead_keys.permute(0, 2, 1)\n",
        "multihead_values = multihead_values.permute(0, 2, 1)\n",
        "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
        "print(\"multihead_values.shape:\", multihead_values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDgVzw354yRd",
        "outputId": "e639d006-ced9-407c-8512-5f56c7195f04"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multihead_keys.shape: torch.Size([3, 24, 6])\n",
            "multihead_values.shape: torch.Size([3, 6, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_multihead_2 = torch.bmm(multihead_query_2.view(3, 1, 24), multihead_keys)\n",
        "print(omega_multihead_2)\n",
        "print(omega_multihead_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0AOLWv45aEm",
        "outputId": "17335bb1-5282-41dd-cdcc-77a6c36e2112"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -0.9446,  -9.9220,  24.6713,   9.3329,  18.5821, -18.7331]],\n",
            "\n",
            "        [[  2.6489,  -8.1238,  -6.9092,  -9.2760,  -5.8502,   1.2093]],\n",
            "\n",
            "        [[  0.3535,   6.1598,  -1.7309,  -0.6793,  -1.9436, -13.1709]]])\n",
            "torch.Size([3, 1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the attention weights \n",
        "import torch.nn.functional as F \n",
        "\n",
        "multihead_attention_weights_2 = F.softmax(omega_multihead_2 / d_k**0.5, dim=0)\n",
        "print(multihead_attention_weights_2)"
      ],
      "metadata": {
        "id": "eZ4Uh7BZ5-1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420cd8ba-adbc-4028-be9b-0a020bff60fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2280, 0.0344, 0.9939, 0.8681, 0.9785, 0.0159]],\n",
            "\n",
            "        [[0.4748, 0.0496, 0.0016, 0.0194, 0.0067, 0.9344]],\n",
            "\n",
            "        [[0.2972, 0.9160, 0.0045, 0.1125, 0.0148, 0.0496]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multihead_context_vector_2 = multihead_attention_weights_2.matmul(multihead_values).view(3, 28)\n",
        "\n",
        "print(multihead_context_vector_2.shape)\n",
        "print(multihead_context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aob94I37nTo",
        "outputId": "4abf9c34-401a-4a8e-d8eb-b70ad0d881ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28])\n",
            "tensor([[-4.0196, -2.8839, -2.7928, -4.8711, -5.3576, -5.6695, -7.1135,  0.4474,\n",
            "         -6.0364, -2.5727, -6.9008, -6.2505, -2.4347, -6.2277, -5.0631, -6.3769,\n",
            "         -5.6076, -0.2504, -7.5703, -2.8492, -2.0196, -3.0125, -3.3246, -2.6591,\n",
            "         -3.9002, -3.3792, -7.1753, -1.9207],\n",
            "        [ 1.8541,  1.3980,  1.3991,  1.9406,  4.3007,  3.2203,  2.7824,  2.3874,\n",
            "          1.9616,  3.5196,  1.0982,  2.4626,  2.7614,  0.8944,  4.2907,  2.2192,\n",
            "          1.4597,  3.4831,  3.7664,  4.9082,  1.3324,  3.0179,  1.8540,  3.0721,\n",
            "          4.9994,  2.8471,  3.5666,  1.9237],\n",
            "        [-1.3329,  1.2958,  1.3449, -1.0297,  0.7839, -0.4812, -0.6817, -1.3890,\n",
            "         -1.6334,  1.5294, -1.2365, -0.2269, -0.7305, -0.6153, -0.3127, -1.6055,\n",
            "         -0.1556,  0.2809,  1.8245, -0.2797, -0.6460,  1.2682,  0.9108,  1.2385,\n",
            "         -0.3255,  0.7398,  0.0181, -0.0865]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sDI5NKD73ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}